---
phase: 01-ml-pipeline-testing
plan: 02
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - backend/tests/integration/test_online_recommender_debug.py
autonomous: true
---

<objective>
Clean up redundant tests and perform a final validation pass to ensure the complete test suite is well-organized and all outputs are sensible.

Purpose: The debug test file duplicates the main online recommender tests with verbose print output. This plan removes redundancy and validates the full suite after Plan 01 lands new tests.
Output: Clean test suite with no redundancy, validated test outputs, confirmed coverage of all offline pipeline and online model logic.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/STATE.md

Files to examine/modify:
@backend/tests/integration/test_online_recommender_debug.py
@backend/tests/integration/test_online_recommender.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Remove redundant debug test file</name>
  <files>backend/tests/integration/test_online_recommender_debug.py</files>
  <action>
Delete backend/tests/integration/test_online_recommender_debug.py entirely.

**Justification:** This file contains 7 tests that are exact functional duplicates of tests in test_online_recommender.py, with the only difference being extensive print() debug output:
- test_known_user_gets_personalised_recs → duplicate of TestKnownUserRecommendations
- test_cold_start_user → duplicate of TestColdStartUser
- test_like_shifts_vector_toward_movie → duplicate of TestLikeShiftsRecommendations
- test_dislike_shifts_vector_away_from_movie → duplicate of TestDislikeShiftsRecommendations
- test_seen_movies_excluded → duplicate of TestSeenMovieExclusion
- test_supercharged_has_double_effect → duplicate of TestSuperchargedSwipe
- test_full_browsing_session → duplicate of TestMultipleSwipesAccumulate

The print debug output adds no assertion value. If verbose debugging is needed, pytest -s already captures print output from the main test file. Keeping duplicates creates maintenance burden and confusion about which tests are canonical.
  </action>
  <verify>cd backend && .venv/bin/python -m pytest tests/integration/ -v --co 2>&1 | grep -c "test_" to confirm debug tests are gone</verify>
  <done>Debug test file removed. Integration test directory contains only test_full_pipeline.py and test_online_recommender.py.</done>
</task>

<task type="auto">
  <name>Task 2: Final test suite validation</name>
  <files>None (validation only)</files>
  <action>
Run the complete test suite and validate that:

1. **All tests pass**: Run `cd backend && .venv/bin/python -m pytest tests/ -v --tb=short` and verify zero failures
2. **Test count**: Should be ~145+ tests (was 122, added ~30+ new in Plan 01, removed 7 debug duplicates)
3. **No warnings about imports or unused fixtures**
4. **Test output makes sense**: Run with `-s` flag on key new test files to verify assertions match the logic:
   - Verify test_build_matrix properly creates sparse matrix with correct dimensions
   - Verify test_recommender_class assertions match the synthetic_artifacts fixture values (e.g., action fan user 1 should score highest on action movies 100 and 103)
5. **Coverage summary**: Run `cd backend && .venv/bin/python -m pytest tests/ --co -q` to list all tests for a final count

Print a summary of the test suite organization:
- Unit tests: count and files
- Integration tests: count and files
- Total test count
  </action>
  <verify>cd backend && .venv/bin/python -m pytest tests/ -v --tb=short 2>&1 | tail -5</verify>
  <done>Full test suite passes with 145+ tests. No regressions. Test outputs verified to be sensible and match expected logic.</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `cd backend && .venv/bin/python -m pytest tests/ -v` — ALL tests pass
- [ ] Debug test file removed, no duplicates remain
- [ ] Final test count is 145+
- [ ] No import warnings or fixture issues
</verification>

<success_criteria>
- Redundant debug test file removed
- Full test suite passes with zero failures
- Test count increased from original 122
- Test suite is well-organized: unit/ for pure functions, integration/ for end-to-end
</success_criteria>

<output>
After completion, create `.planning/phases/01-ml-pipeline-testing/01-02-SUMMARY.md`
</output>
